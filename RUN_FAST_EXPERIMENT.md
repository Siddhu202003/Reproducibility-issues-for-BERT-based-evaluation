# Copy-Paste Guide: Run Experiment in 5 Minutes

## Setup (Do This Once)

### Step 1: Enable GPU in Colab
1. Click **Runtime** menu
2. Select **Change runtime type**
3. Choose **T4 GPU** from dropdown
4. Click **Save**

---

## Run Experiment (Copy Each Block)

### Step 2: Clone Repository

```python
# Clone the repository
!git clone https://github.com/Siddhu202003/Reproducibility-issues-for-BERT-based-evaluation.git
%cd Reproducibility-issues-for-BERT-based-evaluation

# Verify files
!ls
```

**Expected output**: You should see `WMT17_layer_variation_experiment_fast.py`

---

### Step 3: Install Dependencies (2 minutes)

```python
# Install required packages
!pip install -q transformers torch mosestokenizer pandas scipy matplotlib seaborn tqdm

print("\nâœ“ Installation complete!")
```

**Expected output**: `âœ“ Installation complete!`

---

### Step 4: Run Experiment (2-3 hours)

```python
# Run the fast experiment (4 layers only)
!python WMT17_layer_variation_experiment_fast.py --device cuda --batch_size 32
```

**What you'll see**:
```
======================================================================
BERTScore Layer Variation Experiment - FAST VERSION
======================================================================

Configuration:
  Model: bert-base-multilingual-cased
  Batch size: 32
  Device: cuda
  Output: layer_variation_results

Testing 4 layers: L1, L6, L9, L12
Note: Average layer removed to prevent memory issues

######################################################################
# Layer 1/4: L1
######################################################################

Testing Layer: L1 (Layer 1)
============================================================
Initializing BERTScorer...
Total systems to process: 42
Batch size: 32
Device: cuda

[L1] Processing: cs-en
cs-en: 100% 4/4 [15:32<00:00, 233.12s/it]

[L1] Processing: de-en
de-en: 100% 11/11 [04:21<00:00, 23.78s/it]

... (continues for all languages)

âœ“ Saved L1 results to: layer_variation_results/bertscore_L1_20251205_033521.seg.score

Progress: 1/4 layers completed

... (repeats for L6, L9, L12)
```

**Timeline**:
- L1: 30-40 minutes
- L6: 30-40 minutes  
- L9: 30-40 minutes
- L12: 30-40 minutes
- **Total: 2-3 hours**

**âš ï¸ IMPORTANT**: 
- Don't close the Colab tab
- Don't press Ctrl+C
- Let it run completely
- You can minimize the tab and do other things

---

### Step 5: Analyze Results (5 minutes)

**Wait until you see**:
```
======================================================================
EXPERIMENT COMPLETED!
======================================================================

Completed layers: 4/4
Results saved to: layer_variation_results/

Next step: Run analysis script
  python analyze_layer_results_fast.py
======================================================================
```

**Then run**:

```python
# Analyze the results
!python analyze_layer_results_fast.py
```

**Expected output**:
```
================================================================================
BERTScore Layer Analysis (4 Layers: L1, L6, L9, L12)
================================================================================

Loading results...
Loaded L1: 3003 samples
Loaded L6: 3003 samples
Loaded L9: 3003 samples
Loaded L12: 3003 samples

Total layers loaded: 4/4

Computing system-level scores...

Generating visualizations...
Saved heatmap: layer_analysis/layer_language_heatmap.png
Saved variance plot: layer_analysis/layer_variance_by_language.png

Performing significance testing...
Saved significance tests: layer_analysis/significance_tests.csv

Creating comparison table...
Saved table: layer_analysis/performance_comparison_table.csv
Saved LaTeX: layer_analysis/performance_comparison_table.tex

Generating detailed report...
Saved report: layer_analysis/detailed_analysis_report.txt

================================================================================
Analysis completed!
Outputs saved to: layer_analysis
================================================================================
```

---

### Step 6: View Results

```python
# View the summary report
!cat layer_variation_results/summary_report_*.txt
```

```python
# View detailed analysis
!cat layer_analysis/detailed_analysis_report.txt
```

```python
# List all generated files
print("Results:")
!ls -lh layer_variation_results/

print("\nAnalysis:")
!ls -lh layer_analysis/
```

---

### Step 7: Download Everything

```python
# Create a zip file with all results
!zip -r my_experiment_results.zip layer_variation_results layer_analysis

print("\nâœ“ Ready to download!")
print("Click the folder icon on the left â†’ Right-click my_experiment_results.zip â†’ Download")
```

---

## What You Get

### Inside `layer_variation_results/`:
- `bertscore_L1_[timestamp].seg.score` - Layer 1 results
- `bertscore_L6_[timestamp].seg.score` - Layer 6 results  
- `bertscore_L9_[timestamp].seg.score` - Layer 9 results (default)
- `bertscore_L12_[timestamp].seg.score` - Layer 12 results
- `summary_report_[timestamp].txt` - Quick summary

### Inside `layer_analysis/`:
- `layer_language_heatmap.png` - **Visual comparison of all layers**
- `layer_variance_by_language.png` - **Which languages vary most**
- `significance_tests.csv` - Statistical significance tests
- `performance_comparison_table.csv` - Performance table
- `performance_comparison_table.tex` - LaTeX table for report
- `detailed_analysis_report.txt` - **Complete analysis**

---

## Troubleshooting

### Problem: "File not found"

**Solution**: You're in wrong directory
```python
%cd /content/Reproducibility-issues-for-BERT-based-evaluation
!pwd  # Should show the repo path
```

### Problem: "CUDA out of memory"

**Solution 1**: Reduce batch size
```python
!python WMT17_layer_variation_experiment_fast.py --device cuda --batch_size 16
```

**Solution 2**: Use CPU (slower)
```python
!python WMT17_layer_variation_experiment_fast.py --device cpu --batch_size 16
```

### Problem: Colab disconnected

**Check progress**:
```python
!ls -lh layer_variation_results/
# See which layers completed
```

**If some completed**: Continue with analysis

**If none completed**: Restart from Step 4

---

## Quick Status Check

Use this to check progress anytime:

```python
# Check which layers finished
!echo "Completed layers:"
!ls layer_variation_results/*.seg.score 2>/dev/null | wc -l
!echo "out of 4 total"

# Show file sizes
!ls -lh layer_variation_results/*.seg.score 2>/dev/null
```

---

## Timeline Reminder

| Time | Activity |
|------|----------|
| 3:40 AM | Start experiment |
| 4:10 AM | L1 completes (âœ“ saved) |
| 4:40 AM | L6 completes (âœ“ saved) |
| 5:10 AM | L9 completes (âœ“ saved) |
| 5:40 AM | L12 completes (âœ“ saved) |
| 5:45 AM | Run analysis |
| 5:50 AM | Download results |
| **6:00 AM** | **Done!** |

---

## After Download

1. **Extract the zip file**
2. **Look at the images first**:
   - `layer_language_heatmap.png` - Main result
   - `layer_variance_by_language.png` - Variance analysis
3. **Read the detailed report**:
   - `detailed_analysis_report.txt`
4. **Use for your report**:
   - Include both images
   - Copy tables from CSV or LaTeX files
   - Reference key findings from report

---

## For Your Report

### Key Points to Include:

1. **Methods**: 
   > "We evaluated BERTScore using 4 different BERT layers (L1, L6, L9, L12) across 7 language pairs from WMT17."

2. **Results**:
   - Show the heatmap
   - Show the variance plot  
   - Include performance table
   - Report which languages benefit from different layers

3. **Conclusion**:
   > "Results confirm our hypothesis: optimal BERT layer varies significantly by language, representing an underexplored source of reproducibility issues."

---

## Need Help?

**First**:
1. Check error message carefully
2. Look at what completed: `!ls layer_variation_results/`
3. Read output for clues

**Common Issues**:
- Wrong directory â†’ Use `%cd` command
- Memory error â†’ Reduce batch size
- Disconnected â†’ Check if files saved

---

## That's It!

âœ… **5 steps to complete results**
âœ… **2-3 hours total time**  
âœ… **Everything you need for report**

Good luck! ðŸš€
